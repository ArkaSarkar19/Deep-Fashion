{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2005,
     "status": "ok",
     "timestamp": 1616941647055,
     "user": {
      "displayName": "Arka Sarkar",
      "photoUrl": "",
      "userId": "03171226454452371011"
     },
     "user_tz": -330
    },
    "id": "YaYsMAoONLOn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.preprocessing.image import apply_affine_transform\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image \n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "import pickle\n",
    "from keras import optimizers\n",
    "from keras import applications\n",
    "from keras.initializers import glorot_uniform\n",
    "# from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41063,
     "status": "ok",
     "timestamp": 1616941686136,
     "user": {
      "displayName": "Arka Sarkar",
      "photoUrl": "",
      "userId": "03171226454452371011"
     },
     "user_tz": -330
    },
    "id": "r5-SriBjNgPt",
    "outputId": "01cb6e07-5e06-4a54-8177-c7bc3ea19959"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 13892,
     "status": "ok",
     "timestamp": 1616941707543,
     "user": {
      "displayName": "Arka Sarkar",
      "photoUrl": "",
      "userId": "03171226454452371011"
     },
     "user_tz": -330
    },
    "id": "2D_N1uvGNLOz"
   },
   "outputs": [],
   "source": [
    "\n",
    "training_data = pickle.load(open('ACS_training_data_64', 'rb'))\n",
    "labels_dict = pickle.load(open('ACS_training_labels_dict_64', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10560,
     "status": "ok",
     "timestamp": 1616941707547,
     "user": {
      "displayName": "Arka Sarkar",
      "photoUrl": "",
      "userId": "03171226454452371011"
     },
     "user_tz": -330
    },
    "id": "9ImIyX0oNLO1",
    "outputId": "6fb2a0cd-1ba5-4f02-e556-ff5b4b6d8db2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training samples: 71093  shape: (64, 64, 3) shape_label: (15, 1)\n"
     ]
    }
   ],
   "source": [
    "#training data sanity check\n",
    "print('# of training samples:',len(training_data),' shape:',training_data[0][0].shape,\n",
    "      'shape_label:',training_data[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 8958,
     "status": "ok",
     "timestamp": 1616941707548,
     "user": {
      "displayName": "Arka Sarkar",
      "photoUrl": "",
      "userId": "03171226454452371011"
     },
     "user_tz": -330
    },
    "id": "Wu2rWBZVNLO3"
   },
   "outputs": [],
   "source": [
    "train=training_data[:-3000]\n",
    "val_test=training_data[-3000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 8491,
     "status": "ok",
     "timestamp": 1616941707551,
     "user": {
      "displayName": "Arka Sarkar",
      "photoUrl": "",
      "userId": "03171226454452371011"
     },
     "user_tz": -330
    },
    "id": "osO1zYLLNLO5"
   },
   "outputs": [],
   "source": [
    "X=np.array([np.array(i[0]) for i in train])\n",
    "Y=np.array([i[1].reshape((len(labels_dict),)) for i in train])\n",
    "\n",
    "val_test_x=np.array([np.array(i[0]) for i in val_test])\n",
    "val_test_y=np.array([i[1].reshape((len(labels_dict),)) for i in val_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7917,
     "status": "ok",
     "timestamp": 1616941707552,
     "user": {
      "displayName": "Arka Sarkar",
      "photoUrl": "",
      "userId": "03171226454452371011"
     },
     "user_tz": -330
    },
    "id": "gowe8rOKNLO6",
    "outputId": "afb65eb0-a233-42a9-d28c-540b1c0e8e2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((68093, 64, 64, 3), (68093, 15), (3000, 64, 64, 3), (3000, 15))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape, val_test_x.shape, val_test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1445,
     "status": "ok",
     "timestamp": 1616941727538,
     "user": {
      "displayName": "Arka Sarkar",
      "photoUrl": "",
      "userId": "03171226454452371011"
     },
     "user_tz": -330
    },
    "id": "hVW1MxGBNLO9"
   },
   "outputs": [],
   "source": [
    "def CNN_Model(input_shape = (128,128,3), num_classes = 15):\n",
    "    \n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    #Stage 1 \n",
    "    X = Conv2D(64, (5, 5), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X_input)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), strides=(2, 2))(X)\n",
    "    \n",
    "    #Stage 2\n",
    "    X = Conv2D(64, (5, 5), strides = (1, 1), name = 'conv2')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), strides=(2, 2))(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    #Stage 3\n",
    "    X = Conv2D(128, (3, 3), strides = (1, 1), name = 'conv3')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv3')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), strides=(2, 2))(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    #Stage 4 \n",
    "    X = Conv2D(128, (3, 3), strides = (1, 1), name = 'conv4')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv4')(X)\n",
    "    X = Activation('relu')(X)\n",
    "#     X = MaxPooling2D((2, 2), strides=(2, 2))(X)\n",
    "#     X = Dropout(0.2)(X)\n",
    "    \n",
    "#     #Stage 5\n",
    "#     X = Conv2D(256, (1, 1), strides = (1, 1), name = 'conv5')(X)\n",
    "#     X = BatchNormalization(axis = 3, name = 'bn_conv5')(X)\n",
    "#     X = Activation('relu')(X)\n",
    "    \n",
    "    #Stage 6\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1024, activation = 'relu', name = 'fc1')(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    X = Dense(512, activation = 'relu', name = 'fc2')(X)\n",
    "    X = Dense(num_classes, activation='softmax', name='fc3')(X)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name='CNN_Model')\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 2427,
     "status": "ok",
     "timestamp": 1616941939728,
     "user": {
      "displayName": "Arka Sarkar",
      "photoUrl": "",
      "userId": "03171226454452371011"
     },
     "user_tz": -330
    },
    "id": "szv556zhNLO9"
   },
   "outputs": [],
   "source": [
    "adadelta = optimizers.Adadelta(learning_rate=0.01, rho=0.95, epsilon=1e-07)\n",
    "model = CNN_Model(input_shape = (64, 64, 3), num_classes = 15)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = adadelta, metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2386,
     "status": "ok",
     "timestamp": 1616941939733,
     "user": {
      "displayName": "Arka Sarkar",
      "photoUrl": "",
      "userId": "03171226454452371011"
     },
     "user_tz": -330
    },
    "id": "gxacUC9cNLO_",
    "outputId": "4826e067-7704-4952-eab2-5d459fc9e7fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 60, 60, 64)        4864      \n",
      "_________________________________________________________________\n",
      "bn_conv1 (BatchNormalization (None, 60, 60, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 26, 26, 64)        102464    \n",
      "_________________________________________________________________\n",
      "bn_conv2 (BatchNormalization (None, 26, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 11, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "bn_conv3 (BatchNormalization (None, 11, 11, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 3, 3, 128)         147584    \n",
      "_________________________________________________________________\n",
      "bn_conv4 (BatchNormalization (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 1, 1, 256)         33024     \n",
      "_________________________________________________________________\n",
      "bn_conv5 (BatchNormalization (None, 1, 1, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 15)                7695      \n",
      "=================================================================\n",
      "Total params: 1,160,015\n",
      "Trainable params: 1,158,735\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1347351,
     "status": "ok",
     "timestamp": 1616943289827,
     "user": {
      "displayName": "Arka Sarkar",
      "photoUrl": "",
      "userId": "03171226454452371011"
     },
     "user_tz": -330
    },
    "id": "zLruIZb_NLPA",
    "outputId": "f2678387-9d77-4aa6-e521-a68cb979b6fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "266/266 [==============================] - 35s 127ms/step - loss: 2.5744 - accuracy: 0.1362 - val_loss: 2.4233 - val_accuracy: 0.1930\n",
      "Epoch 2/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.4122 - accuracy: 0.1859 - val_loss: 2.3775 - val_accuracy: 0.1953\n",
      "Epoch 3/40\n",
      "266/266 [==============================] - 33s 126ms/step - loss: 2.3782 - accuracy: 0.1979 - val_loss: 2.3520 - val_accuracy: 0.2017\n",
      "Epoch 4/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.3504 - accuracy: 0.2083 - val_loss: 2.3417 - val_accuracy: 0.1977\n",
      "Epoch 5/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.3295 - accuracy: 0.2141 - val_loss: 2.3218 - val_accuracy: 0.2017\n",
      "Epoch 6/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.3100 - accuracy: 0.2220 - val_loss: 2.3126 - val_accuracy: 0.2057\n",
      "Epoch 7/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.3013 - accuracy: 0.2229 - val_loss: 2.3064 - val_accuracy: 0.2093\n",
      "Epoch 8/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2871 - accuracy: 0.2296 - val_loss: 2.2952 - val_accuracy: 0.2033\n",
      "Epoch 9/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2729 - accuracy: 0.2324 - val_loss: 2.2866 - val_accuracy: 0.2177\n",
      "Epoch 10/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2675 - accuracy: 0.2351 - val_loss: 2.2828 - val_accuracy: 0.2130\n",
      "Epoch 11/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2577 - accuracy: 0.2382 - val_loss: 2.2685 - val_accuracy: 0.2257\n",
      "Epoch 12/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2486 - accuracy: 0.2441 - val_loss: 2.2621 - val_accuracy: 0.2243\n",
      "Epoch 13/40\n",
      "266/266 [==============================] - 33s 126ms/step - loss: 2.2432 - accuracy: 0.2454 - val_loss: 2.2597 - val_accuracy: 0.2293\n",
      "Epoch 14/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2261 - accuracy: 0.2500 - val_loss: 2.2630 - val_accuracy: 0.2277\n",
      "Epoch 15/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2192 - accuracy: 0.2540 - val_loss: 2.2457 - val_accuracy: 0.2360\n",
      "Epoch 16/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2139 - accuracy: 0.2543 - val_loss: 2.2368 - val_accuracy: 0.2423\n",
      "Epoch 17/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2056 - accuracy: 0.2577 - val_loss: 2.2450 - val_accuracy: 0.2303\n",
      "Epoch 18/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2054 - accuracy: 0.2616 - val_loss: 2.2286 - val_accuracy: 0.2403\n",
      "Epoch 19/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2028 - accuracy: 0.2620 - val_loss: 2.2165 - val_accuracy: 0.2430\n",
      "Epoch 20/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1943 - accuracy: 0.2631 - val_loss: 2.2189 - val_accuracy: 0.2440\n",
      "Epoch 21/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1882 - accuracy: 0.2634 - val_loss: 2.2006 - val_accuracy: 0.2517\n",
      "Epoch 22/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1792 - accuracy: 0.2666 - val_loss: 2.1935 - val_accuracy: 0.2543\n",
      "Epoch 23/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1795 - accuracy: 0.2715 - val_loss: 2.2104 - val_accuracy: 0.2453\n",
      "Epoch 24/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1702 - accuracy: 0.2734 - val_loss: 2.2064 - val_accuracy: 0.2457\n",
      "Epoch 25/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1692 - accuracy: 0.2709 - val_loss: 2.1933 - val_accuracy: 0.2513\n",
      "Epoch 26/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1538 - accuracy: 0.2779 - val_loss: 2.1982 - val_accuracy: 0.2483\n",
      "Epoch 27/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1555 - accuracy: 0.2766 - val_loss: 2.1843 - val_accuracy: 0.2597\n",
      "Epoch 28/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1571 - accuracy: 0.2756 - val_loss: 2.1822 - val_accuracy: 0.2560\n",
      "Epoch 29/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1599 - accuracy: 0.2731 - val_loss: 2.1778 - val_accuracy: 0.2540\n",
      "Epoch 30/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1446 - accuracy: 0.2800 - val_loss: 2.1729 - val_accuracy: 0.2567\n",
      "Epoch 31/40\n",
      "266/266 [==============================] - 33s 126ms/step - loss: 2.1346 - accuracy: 0.2803 - val_loss: 2.1696 - val_accuracy: 0.2593\n",
      "Epoch 32/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1385 - accuracy: 0.2817 - val_loss: 2.1649 - val_accuracy: 0.2667\n",
      "Epoch 33/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.1349 - accuracy: 0.2834 - val_loss: 2.1714 - val_accuracy: 0.2563\n",
      "Epoch 34/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1247 - accuracy: 0.2854 - val_loss: 2.1465 - val_accuracy: 0.2687\n",
      "Epoch 35/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.1228 - accuracy: 0.2886 - val_loss: 2.1529 - val_accuracy: 0.2670\n",
      "Epoch 36/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1238 - accuracy: 0.2870 - val_loss: 2.1620 - val_accuracy: 0.2567\n",
      "Epoch 37/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.1150 - accuracy: 0.2929 - val_loss: 2.1423 - val_accuracy: 0.2710\n",
      "Epoch 38/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.1110 - accuracy: 0.2900 - val_loss: 2.1400 - val_accuracy: 0.2713\n",
      "Epoch 39/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.0998 - accuracy: 0.2961 - val_loss: 2.1481 - val_accuracy: 0.2660\n",
      "Epoch 40/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.1035 - accuracy: 0.2948 - val_loss: 2.1396 - val_accuracy: 0.2673\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x=X,y=Y,epochs=40,validation_data=(val_test_x,val_test_y),batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5483,
     "status": "ok",
     "timestamp": 1616943631382,
     "user": {
      "displayName": "Arka Sarkar",
      "photoUrl": "",
      "userId": "03171226454452371011"
     },
     "user_tz": -330
    },
    "id": "i9mLaYUjNLPB",
    "outputId": "a58c21ea-bf44-41a4-b4fa-b6c34c5432b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /gdrive/MyDrive/CSE344-Computer-Vision-Project/Clothing_Detection/CNN_Model_40_epoch_29.48_26.73/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('/gdrive/MyDrive/CSE344-Computer-Vision-Project/Clothing_Detection/CNN_Model_40_epoch_29.48_26.73_lr0.01')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1348033,
     "status": "ok",
     "timestamp": 1616945225009,
     "user": {
      "displayName": "Arka Sarkar",
      "photoUrl": "",
      "userId": "03171226454452371011"
     },
     "user_tz": -330
    },
    "id": "cbj_VRzSWbZd",
    "outputId": "57596413-80d0-4eab-f5a9-73526122faf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 60, 60, 64)        4864      \n",
      "_________________________________________________________________\n",
      "bn_conv1 (BatchNormalization (None, 60, 60, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 26, 26, 64)        102464    \n",
      "_________________________________________________________________\n",
      "bn_conv2 (BatchNormalization (None, 26, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 11, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "bn_conv3 (BatchNormalization (None, 11, 11, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 3, 3, 128)         147584    \n",
      "_________________________________________________________________\n",
      "bn_conv4 (BatchNormalization (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 1, 1, 256)         33024     \n",
      "_________________________________________________________________\n",
      "bn_conv5 (BatchNormalization (None, 1, 1, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 15)                7695      \n",
      "=================================================================\n",
      "Total params: 1,160,015\n",
      "Trainable params: 1,158,735\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "266/266 [==============================] - 35s 128ms/step - loss: 2.4955 - accuracy: 0.1598 - val_loss: 2.3833 - val_accuracy: 0.2080\n",
      "Epoch 2/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.3390 - accuracy: 0.2129 - val_loss: 2.3279 - val_accuracy: 0.2050\n",
      "Epoch 3/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.2976 - accuracy: 0.2253 - val_loss: 2.2920 - val_accuracy: 0.2153\n",
      "Epoch 4/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2655 - accuracy: 0.2406 - val_loss: 2.2569 - val_accuracy: 0.2320\n",
      "Epoch 5/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.2396 - accuracy: 0.2466 - val_loss: 2.2769 - val_accuracy: 0.2090\n",
      "Epoch 6/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2172 - accuracy: 0.2524 - val_loss: 2.2626 - val_accuracy: 0.2190\n",
      "Epoch 7/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1984 - accuracy: 0.2576 - val_loss: 2.2196 - val_accuracy: 0.2437\n",
      "Epoch 8/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1773 - accuracy: 0.2656 - val_loss: 2.2557 - val_accuracy: 0.2343\n",
      "Epoch 9/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.1694 - accuracy: 0.2729 - val_loss: 2.1780 - val_accuracy: 0.2517\n",
      "Epoch 10/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1539 - accuracy: 0.2739 - val_loss: 2.2323 - val_accuracy: 0.2393\n",
      "Epoch 11/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1339 - accuracy: 0.2822 - val_loss: 2.1733 - val_accuracy: 0.2590\n",
      "Epoch 12/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.1329 - accuracy: 0.2845 - val_loss: 2.1871 - val_accuracy: 0.2447\n",
      "Epoch 13/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.1217 - accuracy: 0.2848 - val_loss: 2.1338 - val_accuracy: 0.2740\n",
      "Epoch 14/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1139 - accuracy: 0.2869 - val_loss: 2.1509 - val_accuracy: 0.2627\n",
      "Epoch 15/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.0994 - accuracy: 0.2911 - val_loss: 2.1052 - val_accuracy: 0.2840\n",
      "Epoch 16/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.0914 - accuracy: 0.2970 - val_loss: 2.1974 - val_accuracy: 0.2497\n",
      "Epoch 17/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.0801 - accuracy: 0.3024 - val_loss: 2.1292 - val_accuracy: 0.2827\n",
      "Epoch 18/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.0785 - accuracy: 0.3019 - val_loss: 2.0977 - val_accuracy: 0.2920\n",
      "Epoch 19/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.0712 - accuracy: 0.3046 - val_loss: 2.1011 - val_accuracy: 0.2913\n",
      "Epoch 20/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.0650 - accuracy: 0.3070 - val_loss: 2.0989 - val_accuracy: 0.2877\n",
      "Epoch 21/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.0528 - accuracy: 0.3122 - val_loss: 2.0779 - val_accuracy: 0.2980\n",
      "Epoch 22/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.0431 - accuracy: 0.3120 - val_loss: 2.1556 - val_accuracy: 0.2640\n",
      "Epoch 23/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.0372 - accuracy: 0.3161 - val_loss: 2.0592 - val_accuracy: 0.3040\n",
      "Epoch 24/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.0275 - accuracy: 0.3195 - val_loss: 2.0854 - val_accuracy: 0.2970\n",
      "Epoch 25/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.0315 - accuracy: 0.3176 - val_loss: 2.0430 - val_accuracy: 0.3167\n",
      "Epoch 26/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.0234 - accuracy: 0.3184 - val_loss: 2.0469 - val_accuracy: 0.3077\n",
      "Epoch 27/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.0148 - accuracy: 0.3242 - val_loss: 2.0339 - val_accuracy: 0.3120\n",
      "Epoch 28/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.0163 - accuracy: 0.3235 - val_loss: 2.0658 - val_accuracy: 0.2967\n",
      "Epoch 29/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.0077 - accuracy: 0.3250 - val_loss: 2.0486 - val_accuracy: 0.3080\n",
      "Epoch 30/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.0008 - accuracy: 0.3272 - val_loss: 2.0335 - val_accuracy: 0.3197\n",
      "Epoch 31/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 1.9956 - accuracy: 0.3320 - val_loss: 2.0366 - val_accuracy: 0.3173\n",
      "Epoch 32/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 1.9785 - accuracy: 0.3344 - val_loss: 2.0180 - val_accuracy: 0.3203\n",
      "Epoch 33/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 1.9859 - accuracy: 0.3312 - val_loss: 2.0389 - val_accuracy: 0.3183\n",
      "Epoch 34/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 1.9773 - accuracy: 0.3376 - val_loss: 2.0262 - val_accuracy: 0.3097\n",
      "Epoch 35/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 1.9848 - accuracy: 0.3350 - val_loss: 1.9922 - val_accuracy: 0.3297\n",
      "Epoch 36/40\n",
      "266/266 [==============================] - 33s 126ms/step - loss: 1.9719 - accuracy: 0.3380 - val_loss: 2.0022 - val_accuracy: 0.3310\n",
      "Epoch 37/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 1.9700 - accuracy: 0.3412 - val_loss: 1.9833 - val_accuracy: 0.3383\n",
      "Epoch 38/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 1.9585 - accuracy: 0.3444 - val_loss: 2.0227 - val_accuracy: 0.3187\n",
      "Epoch 39/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 1.9585 - accuracy: 0.3425 - val_loss: 1.9753 - val_accuracy: 0.3410\n",
      "Epoch 40/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 1.9553 - accuracy: 0.3421 - val_loss: 1.9894 - val_accuracy: 0.3330\n"
     ]
    }
   ],
   "source": [
    "adadelta = optimizers.Adadelta(learning_rate=0.03, rho=0.95, epsilon=1e-07)\n",
    "model = CNN_Model(input_shape = (64, 64, 3), num_classes = 15)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = adadelta, metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "history=model.fit(x=X,y=Y,epochs=40,validation_data=(val_test_x,val_test_y),batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5474,
     "status": "ok",
     "timestamp": 1616945271607,
     "user": {
      "displayName": "Arka Sarkar",
      "photoUrl": "",
      "userId": "03171226454452371011"
     },
     "user_tz": -330
    },
    "id": "vEG9I3xSXYss",
    "outputId": "f51770c6-f4ed-4d66-9b80-7eb320a15d8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /gdrive/MyDrive/CSE344-Computer-Vision-Project/Clothing_Detection/CNN_Model_40_epoch_34.21_33.3_lr0.03/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('/gdrive/MyDrive/CSE344-Computer-Vision-Project/Clothing_Detection/CNN_Model_40_epoch_34.21_33.3_lr0.03')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 4952,
     "status": "ok",
     "timestamp": 1616945271610,
     "user": {
      "displayName": "Arka Sarkar",
      "photoUrl": "",
      "userId": "03171226454452371011"
     },
     "user_tz": -330
    },
    "id": "rqkNlvO7cr2B",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 60, 60, 64)        4864      \n",
      "_________________________________________________________________\n",
      "bn_conv1 (BatchNormalization (None, 60, 60, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 26, 26, 64)        102464    \n",
      "_________________________________________________________________\n",
      "bn_conv2 (BatchNormalization (None, 26, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 11, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "bn_conv3 (BatchNormalization (None, 11, 11, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 3, 3, 128)         147584    \n",
      "_________________________________________________________________\n",
      "bn_conv4 (BatchNormalization (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 1, 1, 256)         33024     \n",
      "_________________________________________________________________\n",
      "bn_conv5 (BatchNormalization (None, 1, 1, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 15)                7695      \n",
      "=================================================================\n",
      "Total params: 1,160,015\n",
      "Trainable params: 1,158,735\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "266/266 [==============================] - 11s 32ms/step - loss: 2.4790 - accuracy: 0.1692 - val_loss: 2.3319 - val_accuracy: 0.2200\n",
      "Epoch 2/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 2.3163 - accuracy: 0.2206 - val_loss: 2.2581 - val_accuracy: 0.2300\n",
      "Epoch 3/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 2.2580 - accuracy: 0.2358 - val_loss: 2.2179 - val_accuracy: 0.2503\n",
      "Epoch 4/60\n",
      "266/266 [==============================] - 8s 28ms/step - loss: 2.2180 - accuracy: 0.2513 - val_loss: 2.1931 - val_accuracy: 0.2530\n",
      "Epoch 5/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 2.1964 - accuracy: 0.2590 - val_loss: 2.1867 - val_accuracy: 0.2630\n",
      "Epoch 6/60\n",
      "266/266 [==============================] - 8s 28ms/step - loss: 2.1726 - accuracy: 0.2672 - val_loss: 2.1518 - val_accuracy: 0.2753\n",
      "Epoch 7/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 2.1459 - accuracy: 0.2756 - val_loss: 2.1356 - val_accuracy: 0.2783\n",
      "Epoch 8/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 2.1296 - accuracy: 0.2834 - val_loss: 2.1071 - val_accuracy: 0.2867\n",
      "Epoch 9/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 2.1087 - accuracy: 0.2892 - val_loss: 2.0788 - val_accuracy: 0.2947\n",
      "Epoch 10/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 2.1012 - accuracy: 0.2911 - val_loss: 2.0823 - val_accuracy: 0.2907\n",
      "Epoch 11/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 2.0922 - accuracy: 0.2956 - val_loss: 2.0933 - val_accuracy: 0.2897\n",
      "Epoch 12/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 2.0701 - accuracy: 0.3046 - val_loss: 2.0594 - val_accuracy: 0.3020\n",
      "Epoch 13/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 2.0531 - accuracy: 0.3088 - val_loss: 2.0481 - val_accuracy: 0.3060\n",
      "Epoch 14/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 2.0523 - accuracy: 0.3097 - val_loss: 2.0472 - val_accuracy: 0.3117\n",
      "Epoch 15/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 2.0379 - accuracy: 0.3173 - val_loss: 2.0414 - val_accuracy: 0.3093\n",
      "Epoch 16/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 2.0320 - accuracy: 0.3170 - val_loss: 2.0087 - val_accuracy: 0.3203\n",
      "Epoch 17/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 2.0189 - accuracy: 0.3244 - val_loss: 2.0132 - val_accuracy: 0.3223\n",
      "Epoch 18/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 2.0067 - accuracy: 0.3275 - val_loss: 2.0243 - val_accuracy: 0.3233\n",
      "Epoch 19/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 2.0144 - accuracy: 0.3220 - val_loss: 2.0153 - val_accuracy: 0.3157\n",
      "Epoch 20/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.9990 - accuracy: 0.3341 - val_loss: 2.0234 - val_accuracy: 0.3173\n",
      "Epoch 21/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.9889 - accuracy: 0.3351 - val_loss: 2.0076 - val_accuracy: 0.3247\n",
      "Epoch 22/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.9711 - accuracy: 0.3376 - val_loss: 2.0193 - val_accuracy: 0.3263\n",
      "Epoch 23/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.9700 - accuracy: 0.3384 - val_loss: 1.9899 - val_accuracy: 0.3367\n",
      "Epoch 24/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.9745 - accuracy: 0.3392 - val_loss: 1.9531 - val_accuracy: 0.3517\n",
      "Epoch 25/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.9623 - accuracy: 0.3411 - val_loss: 1.9774 - val_accuracy: 0.3263\n",
      "Epoch 26/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.9546 - accuracy: 0.3433 - val_loss: 1.9750 - val_accuracy: 0.3367\n",
      "Epoch 27/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.9403 - accuracy: 0.3487 - val_loss: 1.9583 - val_accuracy: 0.3427\n",
      "Epoch 28/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.9404 - accuracy: 0.3474 - val_loss: 1.9592 - val_accuracy: 0.3427\n",
      "Epoch 29/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.9341 - accuracy: 0.3525 - val_loss: 1.9679 - val_accuracy: 0.3420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.9257 - accuracy: 0.3545 - val_loss: 1.9432 - val_accuracy: 0.3500\n",
      "Epoch 31/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.9234 - accuracy: 0.3544 - val_loss: 1.9310 - val_accuracy: 0.3477\n",
      "Epoch 32/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.9066 - accuracy: 0.3616 - val_loss: 1.9314 - val_accuracy: 0.3507\n",
      "Epoch 33/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.9073 - accuracy: 0.3630 - val_loss: 1.9467 - val_accuracy: 0.3563\n",
      "Epoch 34/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.9003 - accuracy: 0.3641 - val_loss: 1.9380 - val_accuracy: 0.3577\n",
      "Epoch 35/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.9013 - accuracy: 0.3641 - val_loss: 1.9453 - val_accuracy: 0.3473\n",
      "Epoch 36/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.8891 - accuracy: 0.3656 - val_loss: 2.0080 - val_accuracy: 0.3307\n",
      "Epoch 37/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.8900 - accuracy: 0.3673 - val_loss: 1.9665 - val_accuracy: 0.3420\n",
      "Epoch 38/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.8842 - accuracy: 0.3681 - val_loss: 1.9162 - val_accuracy: 0.3583\n",
      "Epoch 39/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.8714 - accuracy: 0.3740 - val_loss: 1.9433 - val_accuracy: 0.3507\n",
      "Epoch 40/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.8712 - accuracy: 0.3739 - val_loss: 1.9044 - val_accuracy: 0.3653\n",
      "Epoch 41/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.8781 - accuracy: 0.3740 - val_loss: 1.9139 - val_accuracy: 0.3600\n",
      "Epoch 42/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.8539 - accuracy: 0.3767 - val_loss: 1.9211 - val_accuracy: 0.3683\n",
      "Epoch 43/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.8603 - accuracy: 0.3750 - val_loss: 1.9320 - val_accuracy: 0.3553\n",
      "Epoch 44/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.8532 - accuracy: 0.3768 - val_loss: 1.9573 - val_accuracy: 0.3413\n",
      "Epoch 45/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.8542 - accuracy: 0.3760 - val_loss: 1.9138 - val_accuracy: 0.3620\n",
      "Epoch 46/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.8377 - accuracy: 0.3866 - val_loss: 1.9035 - val_accuracy: 0.3597\n",
      "Epoch 47/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.8405 - accuracy: 0.3885 - val_loss: 1.8880 - val_accuracy: 0.3570\n",
      "Epoch 48/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.8434 - accuracy: 0.3839 - val_loss: 1.9180 - val_accuracy: 0.3587\n",
      "Epoch 49/60\n",
      "266/266 [==============================] - 8s 31ms/step - loss: 1.8291 - accuracy: 0.3852 - val_loss: 1.9140 - val_accuracy: 0.3587\n",
      "Epoch 50/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.8262 - accuracy: 0.3876 - val_loss: 1.9004 - val_accuracy: 0.3737\n",
      "Epoch 51/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.8207 - accuracy: 0.3898 - val_loss: 1.8857 - val_accuracy: 0.3680\n",
      "Epoch 52/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.8231 - accuracy: 0.3901 - val_loss: 1.9262 - val_accuracy: 0.3450\n",
      "Epoch 53/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.8174 - accuracy: 0.3938 - val_loss: 1.8867 - val_accuracy: 0.3713\n",
      "Epoch 54/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.8113 - accuracy: 0.3938 - val_loss: 1.8911 - val_accuracy: 0.3613\n",
      "Epoch 55/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.8019 - accuracy: 0.3972 - val_loss: 1.8683 - val_accuracy: 0.3783\n",
      "Epoch 56/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.7979 - accuracy: 0.4009 - val_loss: 1.9482 - val_accuracy: 0.3497\n",
      "Epoch 57/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.8009 - accuracy: 0.3982 - val_loss: 1.8615 - val_accuracy: 0.3740\n",
      "Epoch 58/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.8057 - accuracy: 0.3957 - val_loss: 1.8499 - val_accuracy: 0.3747\n",
      "Epoch 59/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.7950 - accuracy: 0.3989 - val_loss: 1.8659 - val_accuracy: 0.3733\n",
      "Epoch 60/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.7843 - accuracy: 0.4054 - val_loss: 1.9049 - val_accuracy: 0.3683\n"
     ]
    }
   ],
   "source": [
    "adadelta = optimizers.Adadelta(learning_rate=0.05, rho=0.95, epsilon=1e-07)\n",
    "model = CNN_Model(input_shape = (64, 64, 3), num_classes = 15)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = adadelta, metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "history=model.fit(x=X,y=Y,epochs=60,validation_data=(val_test_x,val_test_y),batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_Model_60_epoch_40.54_36.83_lr0.05/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('CNN_Model_60_epoch_40.54_36.83_lr0.05')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting sage 5 and the maxpool and batchnorm layers of stage4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 60, 60, 64)        4864      \n",
      "_________________________________________________________________\n",
      "bn_conv1 (BatchNormalization (None, 60, 60, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 26, 26, 64)        102464    \n",
      "_________________________________________________________________\n",
      "bn_conv2 (BatchNormalization (None, 26, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 11, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "bn_conv3 (BatchNormalization (None, 11, 11, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 3, 3, 128)         147584    \n",
      "_________________________________________________________________\n",
      "bn_conv4 (BatchNormalization (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              1180672   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 15)                7695      \n",
      "=================================================================\n",
      "Total params: 2,043,471\n",
      "Trainable params: 2,042,703\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "266/266 [==============================] - 11s 32ms/step - loss: 2.4666 - accuracy: 0.1707 - val_loss: 2.2730 - val_accuracy: 0.2400\n",
      "Epoch 2/60\n",
      "266/266 [==============================] - 7s 28ms/step - loss: 2.2551 - accuracy: 0.2419 - val_loss: 2.1808 - val_accuracy: 0.2630\n",
      "Epoch 3/60\n",
      "266/266 [==============================] - 8s 28ms/step - loss: 2.1702 - accuracy: 0.2707 - val_loss: 2.1403 - val_accuracy: 0.2797\n",
      "Epoch 4/60\n",
      "266/266 [==============================] - 8s 28ms/step - loss: 2.1244 - accuracy: 0.2869 - val_loss: 2.1180 - val_accuracy: 0.2870\n",
      "Epoch 5/60\n",
      "266/266 [==============================] - 8s 28ms/step - loss: 2.0845 - accuracy: 0.3004 - val_loss: 2.0892 - val_accuracy: 0.2977\n",
      "Epoch 6/60\n",
      "266/266 [==============================] - 8s 28ms/step - loss: 2.0509 - accuracy: 0.3115 - val_loss: 2.0874 - val_accuracy: 0.3017\n",
      "Epoch 7/60\n",
      "266/266 [==============================] - 8s 28ms/step - loss: 2.0311 - accuracy: 0.3191 - val_loss: 2.0936 - val_accuracy: 0.2947\n",
      "Epoch 8/60\n",
      "266/266 [==============================] - 8s 28ms/step - loss: 1.9986 - accuracy: 0.3320 - val_loss: 2.0701 - val_accuracy: 0.3107\n",
      "Epoch 9/60\n",
      "266/266 [==============================] - 8s 28ms/step - loss: 1.9806 - accuracy: 0.3384 - val_loss: 2.0028 - val_accuracy: 0.3290\n",
      "Epoch 10/60\n",
      "266/266 [==============================] - 8s 28ms/step - loss: 1.9599 - accuracy: 0.3444 - val_loss: 2.0115 - val_accuracy: 0.3333\n",
      "Epoch 11/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 1.9466 - accuracy: 0.3501 - val_loss: 2.0144 - val_accuracy: 0.3223\n",
      "Epoch 12/60\n",
      "266/266 [==============================] - 8s 28ms/step - loss: 1.9210 - accuracy: 0.3574 - val_loss: 1.9569 - val_accuracy: 0.3437\n",
      "Epoch 13/60\n",
      "266/266 [==============================] - 8s 28ms/step - loss: 1.9169 - accuracy: 0.3598 - val_loss: 1.9460 - val_accuracy: 0.3490\n",
      "Epoch 14/60\n",
      "266/266 [==============================] - 8s 28ms/step - loss: 1.8888 - accuracy: 0.3693 - val_loss: 1.9915 - val_accuracy: 0.3377\n",
      "Epoch 15/60\n",
      "266/266 [==============================] - 8s 28ms/step - loss: 1.8754 - accuracy: 0.3758 - val_loss: 1.9440 - val_accuracy: 0.3563\n",
      "Epoch 16/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 1.8729 - accuracy: 0.3757 - val_loss: 2.0179 - val_accuracy: 0.3297\n",
      "Epoch 17/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 1.8472 - accuracy: 0.3856 - val_loss: 1.9452 - val_accuracy: 0.3570\n",
      "Epoch 18/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 1.8309 - accuracy: 0.3893 - val_loss: 1.9447 - val_accuracy: 0.3507\n",
      "Epoch 19/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 1.8196 - accuracy: 0.3944 - val_loss: 1.9577 - val_accuracy: 0.3443\n",
      "Epoch 20/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 1.8039 - accuracy: 0.3967 - val_loss: 1.9318 - val_accuracy: 0.3633\n",
      "Epoch 21/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.7861 - accuracy: 0.4067 - val_loss: 1.9005 - val_accuracy: 0.3637\n",
      "Epoch 22/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.7787 - accuracy: 0.4099 - val_loss: 1.8900 - val_accuracy: 0.3680\n",
      "Epoch 23/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.7713 - accuracy: 0.4103 - val_loss: 1.9232 - val_accuracy: 0.3603\n",
      "Epoch 24/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 1.7603 - accuracy: 0.4154 - val_loss: 1.8760 - val_accuracy: 0.3827\n",
      "Epoch 25/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.7487 - accuracy: 0.4173 - val_loss: 1.8778 - val_accuracy: 0.3787\n",
      "Epoch 26/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.7381 - accuracy: 0.4242 - val_loss: 1.9424 - val_accuracy: 0.3620\n",
      "Epoch 27/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 1.7184 - accuracy: 0.4318 - val_loss: 1.9068 - val_accuracy: 0.3730\n",
      "Epoch 28/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 1.7068 - accuracy: 0.4312 - val_loss: 1.8782 - val_accuracy: 0.3740\n",
      "Epoch 29/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.7007 - accuracy: 0.4332 - val_loss: 1.9673 - val_accuracy: 0.3567\n",
      "Epoch 30/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 1.6868 - accuracy: 0.4402 - val_loss: 1.8437 - val_accuracy: 0.3923\n",
      "Epoch 31/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.6698 - accuracy: 0.4473 - val_loss: 1.9010 - val_accuracy: 0.3777\n",
      "Epoch 32/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 1.6690 - accuracy: 0.4465 - val_loss: 1.8902 - val_accuracy: 0.3793\n",
      "Epoch 33/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.6526 - accuracy: 0.4533 - val_loss: 1.8377 - val_accuracy: 0.3887\n",
      "Epoch 34/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 8s 29ms/step - loss: 1.6447 - accuracy: 0.4551 - val_loss: 1.8326 - val_accuracy: 0.3977\n",
      "Epoch 35/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 1.6311 - accuracy: 0.4575 - val_loss: 1.8291 - val_accuracy: 0.3893\n",
      "Epoch 36/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 1.6177 - accuracy: 0.4629 - val_loss: 1.8460 - val_accuracy: 0.3953\n",
      "Epoch 37/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 1.6111 - accuracy: 0.4668 - val_loss: 1.8450 - val_accuracy: 0.3923\n",
      "Epoch 38/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 1.5950 - accuracy: 0.4740 - val_loss: 1.8325 - val_accuracy: 0.3957\n",
      "Epoch 39/60\n",
      "266/266 [==============================] - 8s 29ms/step - loss: 1.5907 - accuracy: 0.4755 - val_loss: 1.8631 - val_accuracy: 0.3853\n",
      "Epoch 40/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.5780 - accuracy: 0.4764 - val_loss: 1.8206 - val_accuracy: 0.3937\n",
      "Epoch 41/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.5659 - accuracy: 0.4799 - val_loss: 1.8278 - val_accuracy: 0.4037\n",
      "Epoch 42/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.5636 - accuracy: 0.4838 - val_loss: 1.8645 - val_accuracy: 0.3913\n",
      "Epoch 43/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.5427 - accuracy: 0.4909 - val_loss: 1.8144 - val_accuracy: 0.4043\n",
      "Epoch 44/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.5453 - accuracy: 0.4894 - val_loss: 1.8161 - val_accuracy: 0.4027\n",
      "Epoch 45/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.5243 - accuracy: 0.4935 - val_loss: 1.8350 - val_accuracy: 0.4023\n",
      "Epoch 46/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.5197 - accuracy: 0.4934 - val_loss: 1.8245 - val_accuracy: 0.4003\n",
      "Epoch 47/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.5055 - accuracy: 0.4968 - val_loss: 1.8191 - val_accuracy: 0.4037\n",
      "Epoch 48/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.4955 - accuracy: 0.5064 - val_loss: 1.8277 - val_accuracy: 0.4057\n",
      "Epoch 49/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.4881 - accuracy: 0.5054 - val_loss: 1.8107 - val_accuracy: 0.4063\n",
      "Epoch 50/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.4717 - accuracy: 0.5117 - val_loss: 1.8422 - val_accuracy: 0.4053\n",
      "Epoch 51/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.4646 - accuracy: 0.5125 - val_loss: 1.8381 - val_accuracy: 0.3970\n",
      "Epoch 52/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.4517 - accuracy: 0.5192 - val_loss: 1.8323 - val_accuracy: 0.4133\n",
      "Epoch 53/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.4513 - accuracy: 0.5194 - val_loss: 1.8623 - val_accuracy: 0.4077\n",
      "Epoch 54/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.4328 - accuracy: 0.5258 - val_loss: 1.8075 - val_accuracy: 0.4220\n",
      "Epoch 55/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.4231 - accuracy: 0.5292 - val_loss: 1.8210 - val_accuracy: 0.4087\n",
      "Epoch 56/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.4175 - accuracy: 0.5300 - val_loss: 1.8323 - val_accuracy: 0.4043\n",
      "Epoch 57/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.4032 - accuracy: 0.5314 - val_loss: 1.8153 - val_accuracy: 0.4150\n",
      "Epoch 58/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.3963 - accuracy: 0.5351 - val_loss: 1.8462 - val_accuracy: 0.3920\n",
      "Epoch 59/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.3862 - accuracy: 0.5363 - val_loss: 1.8340 - val_accuracy: 0.4100\n",
      "Epoch 60/60\n",
      "266/266 [==============================] - 8s 30ms/step - loss: 1.3739 - accuracy: 0.5415 - val_loss: 1.8157 - val_accuracy: 0.4127\n"
     ]
    }
   ],
   "source": [
    "adadelta = optimizers.Adadelta(learning_rate=0.05, rho=0.95, epsilon=1e-07)\n",
    "model = CNN_Model(input_shape = (64, 64, 3), num_classes = 15)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = adadelta, metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "history=model.fit(x=X,y=Y,epochs=60,validation_data=(val_test_x,val_test_y),batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_Model_60_epoch_54.15_41.27_lr0.05/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('CNN_Model_60_epoch_54.15_41.27_lr0.05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CNN_Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
