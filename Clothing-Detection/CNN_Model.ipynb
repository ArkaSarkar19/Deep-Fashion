{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YaYsMAoONLOn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.preprocessing.image import apply_affine_transform\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image \n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "import pickle\n",
    "from keras import optimizers\n",
    "from keras import applications\n",
    "from keras.initializers import glorot_uniform\n",
    "# from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r5-SriBjNgPt",
    "outputId": "01cb6e07-5e06-4a54-8177-c7bc3ea19959"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /gdrive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2D_N1uvGNLOz"
   },
   "outputs": [],
   "source": [
    "\n",
    "training_data = pickle.load(open('/gdrive/MyDrive/CSE344-Computer-Vision-Project/Clothing_Detection/ACS_training_data_64', 'rb'))\n",
    "labels_dict = pickle.load(open('/gdrive/MyDrive/CSE344-Computer-Vision-Project/Clothing_Detection/ACS_training_labels_dict_64', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ImIyX0oNLO1",
    "outputId": "6fb2a0cd-1ba5-4f02-e556-ff5b4b6d8db2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training samples: 71093  shape: (64, 64, 3) shape_label: (15, 1)\n"
     ]
    }
   ],
   "source": [
    "#training data sanity check\n",
    "print('# of training samples:',len(training_data),' shape:',training_data[0][0].shape,\n",
    "      'shape_label:',training_data[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Wu2rWBZVNLO3"
   },
   "outputs": [],
   "source": [
    "train=training_data[:-3000]\n",
    "val_test=training_data[-3000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "osO1zYLLNLO5"
   },
   "outputs": [],
   "source": [
    "X=np.array([np.array(i[0]) for i in train])\n",
    "Y=np.array([i[1].reshape((len(labels_dict),)) for i in train])\n",
    "\n",
    "val_test_x=np.array([np.array(i[0]) for i in val_test])\n",
    "val_test_y=np.array([i[1].reshape((len(labels_dict),)) for i in val_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gowe8rOKNLO6",
    "outputId": "afb65eb0-a233-42a9-d28c-540b1c0e8e2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((68093, 64, 64, 3), (68093, 15), (3000, 64, 64, 3), (3000, 15))"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape, val_test_x.shape, val_test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hVW1MxGBNLO9"
   },
   "outputs": [],
   "source": [
    "def CNN_Model(input_shape = (128,128,3), num_classes = 15):\n",
    "    \n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    #Stage 1 \n",
    "    X = Conv2D(64, (5, 5), strides = (1, 1), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X_input)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), strides=(2, 2))(X)\n",
    "    \n",
    "    #Stage 2\n",
    "    X = Conv2D(64, (5, 5), strides = (1, 1), name = 'conv2')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), strides=(2, 2))(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    #Stage 3\n",
    "    X = Conv2D(128, (3, 3), strides = (1, 1), name = 'conv3')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv3')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), strides=(2, 2))(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    #Stage 4 \n",
    "    X = Conv2D(128, (3, 3), strides = (1, 1), name = 'conv4')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv4')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), strides=(2, 2))(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    \n",
    "    #Stage 5\n",
    "    X = Conv2D(256, (1, 1), strides = (1, 1), name = 'conv5')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv5')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    #Stage 6\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1024, activation = 'relu', name = 'fc1')(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    X = Dense(512, activation = 'relu', name = 'fc2')(X)\n",
    "    X = Dense(num_classes, activation='softmax', name='fc3')(X)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name='CNN_Model')\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "szv556zhNLO9"
   },
   "outputs": [],
   "source": [
    "adadelta = optimizers.Adadelta(learning_rate=0.01, rho=0.95, epsilon=1e-07)\n",
    "model = CNN_Model(input_shape = (64, 64, 3), num_classes = 15)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = adadelta, metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gxacUC9cNLO_",
    "outputId": "4826e067-7704-4952-eab2-5d459fc9e7fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 60, 60, 64)        4864      \n",
      "_________________________________________________________________\n",
      "bn_conv1 (BatchNormalization (None, 60, 60, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 26, 26, 64)        102464    \n",
      "_________________________________________________________________\n",
      "bn_conv2 (BatchNormalization (None, 26, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 11, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "bn_conv3 (BatchNormalization (None, 11, 11, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 3, 3, 128)         147584    \n",
      "_________________________________________________________________\n",
      "bn_conv4 (BatchNormalization (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 1, 1, 256)         33024     \n",
      "_________________________________________________________________\n",
      "bn_conv5 (BatchNormalization (None, 1, 1, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 15)                7695      \n",
      "=================================================================\n",
      "Total params: 1,160,015\n",
      "Trainable params: 1,158,735\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zLruIZb_NLPA",
    "outputId": "f2678387-9d77-4aa6-e521-a68cb979b6fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "266/266 [==============================] - 35s 127ms/step - loss: 2.5744 - accuracy: 0.1362 - val_loss: 2.4233 - val_accuracy: 0.1930\n",
      "Epoch 2/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.4122 - accuracy: 0.1859 - val_loss: 2.3775 - val_accuracy: 0.1953\n",
      "Epoch 3/40\n",
      "266/266 [==============================] - 33s 126ms/step - loss: 2.3782 - accuracy: 0.1979 - val_loss: 2.3520 - val_accuracy: 0.2017\n",
      "Epoch 4/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.3504 - accuracy: 0.2083 - val_loss: 2.3417 - val_accuracy: 0.1977\n",
      "Epoch 5/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.3295 - accuracy: 0.2141 - val_loss: 2.3218 - val_accuracy: 0.2017\n",
      "Epoch 6/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.3100 - accuracy: 0.2220 - val_loss: 2.3126 - val_accuracy: 0.2057\n",
      "Epoch 7/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.3013 - accuracy: 0.2229 - val_loss: 2.3064 - val_accuracy: 0.2093\n",
      "Epoch 8/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2871 - accuracy: 0.2296 - val_loss: 2.2952 - val_accuracy: 0.2033\n",
      "Epoch 9/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2729 - accuracy: 0.2324 - val_loss: 2.2866 - val_accuracy: 0.2177\n",
      "Epoch 10/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2675 - accuracy: 0.2351 - val_loss: 2.2828 - val_accuracy: 0.2130\n",
      "Epoch 11/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2577 - accuracy: 0.2382 - val_loss: 2.2685 - val_accuracy: 0.2257\n",
      "Epoch 12/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2486 - accuracy: 0.2441 - val_loss: 2.2621 - val_accuracy: 0.2243\n",
      "Epoch 13/40\n",
      "266/266 [==============================] - 33s 126ms/step - loss: 2.2432 - accuracy: 0.2454 - val_loss: 2.2597 - val_accuracy: 0.2293\n",
      "Epoch 14/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2261 - accuracy: 0.2500 - val_loss: 2.2630 - val_accuracy: 0.2277\n",
      "Epoch 15/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2192 - accuracy: 0.2540 - val_loss: 2.2457 - val_accuracy: 0.2360\n",
      "Epoch 16/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2139 - accuracy: 0.2543 - val_loss: 2.2368 - val_accuracy: 0.2423\n",
      "Epoch 17/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2056 - accuracy: 0.2577 - val_loss: 2.2450 - val_accuracy: 0.2303\n",
      "Epoch 18/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2054 - accuracy: 0.2616 - val_loss: 2.2286 - val_accuracy: 0.2403\n",
      "Epoch 19/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2028 - accuracy: 0.2620 - val_loss: 2.2165 - val_accuracy: 0.2430\n",
      "Epoch 20/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1943 - accuracy: 0.2631 - val_loss: 2.2189 - val_accuracy: 0.2440\n",
      "Epoch 21/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1882 - accuracy: 0.2634 - val_loss: 2.2006 - val_accuracy: 0.2517\n",
      "Epoch 22/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1792 - accuracy: 0.2666 - val_loss: 2.1935 - val_accuracy: 0.2543\n",
      "Epoch 23/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1795 - accuracy: 0.2715 - val_loss: 2.2104 - val_accuracy: 0.2453\n",
      "Epoch 24/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1702 - accuracy: 0.2734 - val_loss: 2.2064 - val_accuracy: 0.2457\n",
      "Epoch 25/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1692 - accuracy: 0.2709 - val_loss: 2.1933 - val_accuracy: 0.2513\n",
      "Epoch 26/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1538 - accuracy: 0.2779 - val_loss: 2.1982 - val_accuracy: 0.2483\n",
      "Epoch 27/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1555 - accuracy: 0.2766 - val_loss: 2.1843 - val_accuracy: 0.2597\n",
      "Epoch 28/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1571 - accuracy: 0.2756 - val_loss: 2.1822 - val_accuracy: 0.2560\n",
      "Epoch 29/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1599 - accuracy: 0.2731 - val_loss: 2.1778 - val_accuracy: 0.2540\n",
      "Epoch 30/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1446 - accuracy: 0.2800 - val_loss: 2.1729 - val_accuracy: 0.2567\n",
      "Epoch 31/40\n",
      "266/266 [==============================] - 33s 126ms/step - loss: 2.1346 - accuracy: 0.2803 - val_loss: 2.1696 - val_accuracy: 0.2593\n",
      "Epoch 32/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1385 - accuracy: 0.2817 - val_loss: 2.1649 - val_accuracy: 0.2667\n",
      "Epoch 33/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.1349 - accuracy: 0.2834 - val_loss: 2.1714 - val_accuracy: 0.2563\n",
      "Epoch 34/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1247 - accuracy: 0.2854 - val_loss: 2.1465 - val_accuracy: 0.2687\n",
      "Epoch 35/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.1228 - accuracy: 0.2886 - val_loss: 2.1529 - val_accuracy: 0.2670\n",
      "Epoch 36/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1238 - accuracy: 0.2870 - val_loss: 2.1620 - val_accuracy: 0.2567\n",
      "Epoch 37/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.1150 - accuracy: 0.2929 - val_loss: 2.1423 - val_accuracy: 0.2710\n",
      "Epoch 38/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.1110 - accuracy: 0.2900 - val_loss: 2.1400 - val_accuracy: 0.2713\n",
      "Epoch 39/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.0998 - accuracy: 0.2961 - val_loss: 2.1481 - val_accuracy: 0.2660\n",
      "Epoch 40/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.1035 - accuracy: 0.2948 - val_loss: 2.1396 - val_accuracy: 0.2673\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x=X,y=Y,epochs=40,validation_data=(val_test_x,val_test_y),batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i9mLaYUjNLPB",
    "outputId": "a58c21ea-bf44-41a4-b4fa-b6c34c5432b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /gdrive/MyDrive/CSE344-Computer-Vision-Project/Clothing_Detection/CNN_Model_40_epoch_29.48_26.73/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('/gdrive/MyDrive/CSE344-Computer-Vision-Project/Clothing_Detection/CNN_Model_40_epoch_29.48_26.73_lr0.01')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cbj_VRzSWbZd",
    "outputId": "57596413-80d0-4eab-f5a9-73526122faf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 60, 60, 64)        4864      \n",
      "_________________________________________________________________\n",
      "bn_conv1 (BatchNormalization (None, 60, 60, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 26, 26, 64)        102464    \n",
      "_________________________________________________________________\n",
      "bn_conv2 (BatchNormalization (None, 26, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 11, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "bn_conv3 (BatchNormalization (None, 11, 11, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 3, 3, 128)         147584    \n",
      "_________________________________________________________________\n",
      "bn_conv4 (BatchNormalization (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 1, 1, 256)         33024     \n",
      "_________________________________________________________________\n",
      "bn_conv5 (BatchNormalization (None, 1, 1, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 15)                7695      \n",
      "=================================================================\n",
      "Total params: 1,160,015\n",
      "Trainable params: 1,158,735\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "266/266 [==============================] - 35s 128ms/step - loss: 2.4955 - accuracy: 0.1598 - val_loss: 2.3833 - val_accuracy: 0.2080\n",
      "Epoch 2/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.3390 - accuracy: 0.2129 - val_loss: 2.3279 - val_accuracy: 0.2050\n",
      "Epoch 3/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.2976 - accuracy: 0.2253 - val_loss: 2.2920 - val_accuracy: 0.2153\n",
      "Epoch 4/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2655 - accuracy: 0.2406 - val_loss: 2.2569 - val_accuracy: 0.2320\n",
      "Epoch 5/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.2396 - accuracy: 0.2466 - val_loss: 2.2769 - val_accuracy: 0.2090\n",
      "Epoch 6/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.2172 - accuracy: 0.2524 - val_loss: 2.2626 - val_accuracy: 0.2190\n",
      "Epoch 7/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1984 - accuracy: 0.2576 - val_loss: 2.2196 - val_accuracy: 0.2437\n",
      "Epoch 8/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1773 - accuracy: 0.2656 - val_loss: 2.2557 - val_accuracy: 0.2343\n",
      "Epoch 9/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.1694 - accuracy: 0.2729 - val_loss: 2.1780 - val_accuracy: 0.2517\n",
      "Epoch 10/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1539 - accuracy: 0.2739 - val_loss: 2.2323 - val_accuracy: 0.2393\n",
      "Epoch 11/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1339 - accuracy: 0.2822 - val_loss: 2.1733 - val_accuracy: 0.2590\n",
      "Epoch 12/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.1329 - accuracy: 0.2845 - val_loss: 2.1871 - val_accuracy: 0.2447\n",
      "Epoch 13/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.1217 - accuracy: 0.2848 - val_loss: 2.1338 - val_accuracy: 0.2740\n",
      "Epoch 14/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.1139 - accuracy: 0.2869 - val_loss: 2.1509 - val_accuracy: 0.2627\n",
      "Epoch 15/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.0994 - accuracy: 0.2911 - val_loss: 2.1052 - val_accuracy: 0.2840\n",
      "Epoch 16/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.0914 - accuracy: 0.2970 - val_loss: 2.1974 - val_accuracy: 0.2497\n",
      "Epoch 17/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.0801 - accuracy: 0.3024 - val_loss: 2.1292 - val_accuracy: 0.2827\n",
      "Epoch 18/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.0785 - accuracy: 0.3019 - val_loss: 2.0977 - val_accuracy: 0.2920\n",
      "Epoch 19/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.0712 - accuracy: 0.3046 - val_loss: 2.1011 - val_accuracy: 0.2913\n",
      "Epoch 20/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.0650 - accuracy: 0.3070 - val_loss: 2.0989 - val_accuracy: 0.2877\n",
      "Epoch 21/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.0528 - accuracy: 0.3122 - val_loss: 2.0779 - val_accuracy: 0.2980\n",
      "Epoch 22/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.0431 - accuracy: 0.3120 - val_loss: 2.1556 - val_accuracy: 0.2640\n",
      "Epoch 23/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.0372 - accuracy: 0.3161 - val_loss: 2.0592 - val_accuracy: 0.3040\n",
      "Epoch 24/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.0275 - accuracy: 0.3195 - val_loss: 2.0854 - val_accuracy: 0.2970\n",
      "Epoch 25/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.0315 - accuracy: 0.3176 - val_loss: 2.0430 - val_accuracy: 0.3167\n",
      "Epoch 26/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.0234 - accuracy: 0.3184 - val_loss: 2.0469 - val_accuracy: 0.3077\n",
      "Epoch 27/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.0148 - accuracy: 0.3242 - val_loss: 2.0339 - val_accuracy: 0.3120\n",
      "Epoch 28/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 2.0163 - accuracy: 0.3235 - val_loss: 2.0658 - val_accuracy: 0.2967\n",
      "Epoch 29/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.0077 - accuracy: 0.3250 - val_loss: 2.0486 - val_accuracy: 0.3080\n",
      "Epoch 30/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 2.0008 - accuracy: 0.3272 - val_loss: 2.0335 - val_accuracy: 0.3197\n",
      "Epoch 31/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 1.9956 - accuracy: 0.3320 - val_loss: 2.0366 - val_accuracy: 0.3173\n",
      "Epoch 32/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 1.9785 - accuracy: 0.3344 - val_loss: 2.0180 - val_accuracy: 0.3203\n",
      "Epoch 33/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 1.9859 - accuracy: 0.3312 - val_loss: 2.0389 - val_accuracy: 0.3183\n",
      "Epoch 34/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 1.9773 - accuracy: 0.3376 - val_loss: 2.0262 - val_accuracy: 0.3097\n",
      "Epoch 35/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 1.9848 - accuracy: 0.3350 - val_loss: 1.9922 - val_accuracy: 0.3297\n",
      "Epoch 36/40\n",
      "266/266 [==============================] - 33s 126ms/step - loss: 1.9719 - accuracy: 0.3380 - val_loss: 2.0022 - val_accuracy: 0.3310\n",
      "Epoch 37/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 1.9700 - accuracy: 0.3412 - val_loss: 1.9833 - val_accuracy: 0.3383\n",
      "Epoch 38/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 1.9585 - accuracy: 0.3444 - val_loss: 2.0227 - val_accuracy: 0.3187\n",
      "Epoch 39/40\n",
      "266/266 [==============================] - 34s 126ms/step - loss: 1.9585 - accuracy: 0.3425 - val_loss: 1.9753 - val_accuracy: 0.3410\n",
      "Epoch 40/40\n",
      "266/266 [==============================] - 34s 127ms/step - loss: 1.9553 - accuracy: 0.3421 - val_loss: 1.9894 - val_accuracy: 0.3330\n"
     ]
    }
   ],
   "source": [
    "adadelta = optimizers.Adadelta(learning_rate=0.03, rho=0.95, epsilon=1e-07)\n",
    "model = CNN_Model(input_shape = (64, 64, 3), num_classes = 15)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = adadelta, metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "history=model.fit(x=X,y=Y,epochs=40,validation_data=(val_test_x,val_test_y),batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vEG9I3xSXYss",
    "outputId": "f51770c6-f4ed-4d66-9b80-7eb320a15d8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /gdrive/MyDrive/CSE344-Computer-Vision-Project/Clothing_Detection/CNN_Model_40_epoch_34.21_33.3_lr0.03/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('/gdrive/MyDrive/CSE344-Computer-Vision-Project/Clothing_Detection/CNN_Model_40_epoch_34.21_33.3_lr0.03')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "rqkNlvO7cr2B"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CNN_Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
